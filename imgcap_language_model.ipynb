{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, Dropout, Dense\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = 'data/Flickr8k.token.txt'\n",
    "img_to_caps = dict()\n",
    "\n",
    "with open(fname, 'r') as f:\n",
    "    for line in f:\n",
    "        tokens = line.split(' ')\n",
    "        img_fname, num = tokens[0].split('#')\n",
    "        caption = ' '.join(tokens[1:]).strip()\n",
    "        if img_fname not in img_to_caps: img_to_caps[img_fname] = []\n",
    "        img_to_caps[img_fname].append(caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_vocab = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tk = text.Tokenizer(nb_words=n_vocab)\n",
    "\n",
    "texts = []\n",
    "for img_name in img_to_caps:\n",
    "    texts += img_to_caps[img_name]\n",
    "\n",
    "tk.fit_on_texts(texts)\n",
    "sorted_word_counts = sorted(tk.word_counts.items(), key=lambda x: x[1])\n",
    "sorted_word_counts = sorted_word_counts[::-1][:n_vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_to_int = {t[0]: i for i,t in enumerate(sorted_word_counts)}\n",
    "int_to_word = {i: t[0] for i,t in enumerate(sorted_word_counts)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_seq_len = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_to_seqs = {}\n",
    "for img_fname, captions in img_to_caps.items():\n",
    "    seqs = []\n",
    "    for caption in captions:\n",
    "        seqs.append([word_to_int[w] for w in caption.split() if w in word_to_int])\n",
    "    img_to_seqs[img_fname] = seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_to_padded_seqs, img_to_next_chars = {}, {}\n",
    "for img_fname, seqs in img_to_seqs.items():\n",
    "    partial_seqs = []\n",
    "    next_words = []\n",
    "    for seq in seqs:\n",
    "        for i in range(1,len(seq)):\n",
    "            partial_seqs.append(seq[:i])\n",
    "            next_words.append(seq[i])\n",
    "    padded_partial_seqs = sequence.pad_sequences(partial_seqs, max_seq_len)\n",
    "    \n",
    "    next_words_1hot = np.zeros([len(next_words), n_vocab], dtype=np.bool)\n",
    "    for i,next_word in enumerate(next_words):\n",
    "        next_words_1hot[i,next_word] = 1\n",
    "    \n",
    "    img_to_padded_seqs[img_fname] = padded_partial_seqs\n",
    "    img_to_next_chars[img_fname] = next_words_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_lst, y_lst = [], []\n",
    "for img_fname in img_to_padded_seqs:\n",
    "    X_lst.append(img_to_padded_seqs[img_fname])\n",
    "    y_lst.append(img_to_next_chars[img_fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = np.concatenate(X_lst, axis=0), np.concatenate(y_lst, axis=0)\n",
    "X = np.expand_dims(X, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X = np.zeros([n_seqs, max_seq_len, n_vocab], dtype=np.bool)\n",
    "# y = np.zeros([n_seqs, n_vocab], dtype=np.bool)\n",
    "\n",
    "# for i,seq in enumerate(seqs):\n",
    "#     for j,c in enumerate(seq):\n",
    "#         X[i,j,char_to_int[c]] = 1\n",
    "#     y[i,char_to_int[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(256, input_shape=(max_seq_len,1)))\n",
    "model.add(Dense(n_vocab,activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint('weights.{epoch:02d}-{loss:.2f}.hdf5', monitor='loss', verbose=0,\n",
    "                                  save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=True, write_images=False)\n",
    "callbacks_list = [model_checkpoint, tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "219751/219751 [==============================] - 63s - loss: 3.3730    \n",
      "Epoch 2/20\n",
      "219751/219751 [==============================] - 62s - loss: 3.1490    \n",
      "Epoch 3/20\n",
      "219751/219751 [==============================] - 62s - loss: 3.0383    \n",
      "Epoch 4/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.9550    \n",
      "Epoch 5/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.8955    \n",
      "Epoch 6/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.8526    \n",
      "Epoch 7/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.8171    \n",
      "Epoch 8/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.7845    \n",
      "Epoch 9/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.7563    \n",
      "Epoch 10/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.7296    \n",
      "Epoch 11/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.7041    \n",
      "Epoch 12/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.6810    \n",
      "Epoch 13/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.6600    \n",
      "Epoch 14/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.6394    \n",
      "Epoch 15/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.6206    \n",
      "Epoch 16/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.6016    \n",
      "Epoch 17/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.5846    \n",
      "Epoch 18/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.5687    \n",
      "Epoch 19/20\n",
      "219751/219751 [==============================] - 63s - loss: 2.5532    \n",
      "Epoch 20/20\n",
      "219751/219751 [==============================] - 62s - loss: 2.5397    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3b5d979c88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to train\n",
    "\n",
    "# nb_epoch = 20\n",
    "# batch_size = 128\n",
    "# model.fit(X, y, nb_epoch=nb_epoch, batch_size=batch_size, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading model from weight\n",
    "\n",
    "weight_fname = 'imgcap_language_weights.hdf5'\n",
    "model.load_weights(weight_fname)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children \n",
      "are playing in a water in the snow and to the ball in a red shirt and blue next is a green with a in its mouth in the background her her her the water her the other in the air the ball in the background and a dog is a in the air to another her the water behind to the other in the red and another is wearing a ball in a pool and a dog in the background with a background in the background in front of a man with a woman and a of with a "
     ]
    }
   ],
   "source": [
    "# Generate random start\n",
    "\n",
    "num_iter = 100\n",
    "curr_seq = np.zeros([1,max_seq_len,1])\n",
    "curr_seq[0,:,0] = X[np.random.randint(X.shape[0])].reshape(1,-1)\n",
    "\n",
    "for i in curr_seq[0,:,0]:\n",
    "    if i != 0: print(sorted_word_counts[int(i)][0], end=' ')\n",
    "print()\n",
    "\n",
    "for i in range(num_iter):\n",
    "    prediction = model.predict(curr_seq)\n",
    "    idx = np.argmax(prediction)\n",
    "    next_word = sorted_word_counts[idx][0]\n",
    "    curr_seq[0,:max_seq_len-1,0] = curr_seq[0,1:,0]\n",
    "    curr_seq[0,max_seq_len-1,0] = idx\n",
    "    print(next_word, end=' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
